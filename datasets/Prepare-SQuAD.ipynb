{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76d2b593-3099-4c49-bbff-84d340f42462",
   "metadata": {},
   "source": [
    "# Sample data preparation: SQuAD question answering\n",
    "\n",
    "> *This notebook has been tested in the Python 3 kernel of SageMaker Studio JupyterLab (Distribution v2.0)*\n",
    "\n",
    "This notebook records the steps we took to transform and prepare a small extract of the [Stanford Question Answering Dataset (SQuAD) v2.0](https://rajpurkar.github.io/SQuAD-explorer/) for use with Foundation Model Evaluation Jobs [in Amazon Bedrock](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation.html) and [in Amazon SageMaker](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-foundation-model-evaluate.html).\n",
    "\n",
    "You don't need to re-run it (unless you want to explore further): The output files are saved in this folder of the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c0fd10-e3e2-4623-be8e-00ce71c9d845",
   "metadata": {},
   "source": [
    "## Imports and setup\n",
    "\n",
    "This notebook optionally uses [OpenPyXL](https://openpyxl.readthedocs.io/en/stable/tutorial.html) to demonstrate working with `.xlsx` files from Python. This library isn't installed in the SageMaker Studio Python kernel by default, so you'll need to install it to run that section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86c7216c-2648-4893-b715-08767359ce4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in /opt/conda/lib/python3.11/site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b653135-ec25-42ea-848e-572949eb788d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Python Built-Ins:\n",
    "import csv\n",
    "import json\n",
    "import os\n",
    "from shutil import rmtree\n",
    "from string import Template\n",
    "from typing import Dict, List\n",
    "\n",
    "# External Dependencies:\n",
    "import openpyxl  # Utilities for working with .xls[x] spreadsheets\n",
    "import pandas as pd  # Utilities for working with dataframes (tabular data)\n",
    "from tqdm.notebook import tqdm  # Progress bars\n",
    "\n",
    "os.makedirs(\"raw/squad\", exist_ok=True)  # Raw source data\n",
    "os.makedirs(\"question-answering\", exist_ok=True)  # Transformed output dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787b10f6-f1dd-42bb-9537-d6572794431e",
   "metadata": {},
   "source": [
    "## Fetch and pre-process raw SQuAD data\n",
    "\n",
    "This sample uses (a small subset of) the [Stanford Question Answering Dataset (SQuAD) v2.0](https://rajpurkar.github.io/SQuAD-explorer/), development partition. SQuAD (also available [on Hugging Face Datasets](https://huggingface.co/datasets/rajpurkar/squad_v2)) is distributed under the CC BY-SA 4.0 license.\n",
    "\n",
    "First we'll fetch the raw JSON dataset from the original source:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "931ddaef-4b59-4fc7-a18f-d87dc0b86abf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-10-25 08:59:13--  https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json\n",
      "Resolving rajpurkar.github.io (rajpurkar.github.io)... 185.199.109.153, 185.199.110.153, 185.199.108.153, ...\n",
      "Connecting to rajpurkar.github.io (rajpurkar.github.io)|185.199.109.153|:443... connected.\n",
      "WARNING: cannot verify rajpurkar.github.io's certificate, issued by ‘CN=DigiCert Global G2 TLS RSA SHA256 2020 CA1,O=DigiCert Inc,C=US’:\n",
      "  Unable to locally verify the issuer's authority.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4370528 (4.2M) [application/json]\n",
      "Saving to: ‘raw/squad/squad-dev-v2.0.json’\n",
      "\n",
      "raw/squad/squad-dev 100%[===================>]   4.17M  --.-KB/s    in 0.01s   \n",
      "\n",
      "2024-10-25 08:59:13 (306 MB/s) - ‘raw/squad/squad-dev-v2.0.json’ saved [4370528/4370528]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget --no-check-certificate -O raw/squad/squad-dev-v2.0.json \\\n",
    "    https://rajpurkar.github.io/SQuAD-explorer/dataset/dev-v2.0.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e525f1c-74dc-4b52-bf1f-420a61b1b3ee",
   "metadata": {},
   "source": [
    "SQuAD is based on Wikipedia articles and demonstrates **extractive question answering in context**: Each paragraph of an article is linked to a set of questions that paragraph directly answers, and links to which exact span(s) of text answers each question.\n",
    "\n",
    "For our case we'd like to demonstrate a **RAG-like** use-case, so we'll concatenate the paragraphs of each article together into one overall \"document\", and sample just one question per article. We'll keep the dataset usable with models with smaller *context windows*, by limiting a maximum number of paragraphs we consider for each article; and also limit the *total* number of questions we generate, to keep the dataset practical for human evaluation demos.\n",
    "\n",
    "We'll output:\n",
    "\n",
    "1. The result into a [JSON-Lines](https://jsonlines.org/) format where each line/record contains:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"doc\": \"...\", // Text of the article\n",
    "    \"doc_id\": \"...\", // Unique ID (title) of the article\n",
    "    \"question\": \"...\", // Text of the question\n",
    "    \"question_id\": \"...\", // Unique SQuAD ID of the question\n",
    "    \"answers\": [\"...\", \"...\"], // Set of (potentially multiple) reference answer texts\n",
    "}\n",
    "```\n",
    "\n",
    "2. The collated source documents as `.txt` files under a `corpus` subfolder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e26119fe-592e-4e83-b963-58d8fb861454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0bd6b9e5b2044a587b2184868a5bf4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 20 questions from 20 documents\n"
     ]
    }
   ],
   "source": [
    "MAX_PARAS = 5  # Limit each generated example's max length\n",
    "MAX_QS = 20  # Limit total number of examples to be generated\n",
    "n_docs = 0\n",
    "n_qs = 0\n",
    "\n",
    "rmtree(\"question-answering/corpus\", ignore_errors=True)\n",
    "os.makedirs(\"question-answering/corpus\")\n",
    "\n",
    "with open(\"raw/squad/squad-dev-v2.0.json\") as fin:\n",
    "    raw = json.load(fin)\n",
    "    with open(\"question-answering/qa.manifest.jsonl\", \"w\") as fout:\n",
    "        for doc_data in tqdm(raw[\"data\"]):\n",
    "            n_docs += 1\n",
    "            doc_id = doc_data[\"title\"]\n",
    "            paragraphs = doc_data[\"paragraphs\"][:MAX_PARAS]\n",
    "            doc_text = \"\\n\\n\".join(para[\"context\"] for para in paragraphs)\n",
    "            with open(f\"question-answering/corpus/{doc_id}.txt\", \"w\") as fdoc:\n",
    "                fdoc.write(doc_text)\n",
    "            for para in paragraphs:\n",
    "                for qa in para[\"qas\"]:\n",
    "                    if qa[\"is_impossible\"]:\n",
    "                        continue\n",
    "                    if n_qs > 0:\n",
    "                        fout.write(\"\\n\")\n",
    "                    # We use dict over 'set' here to keep deterministic order:\n",
    "                    answers = {ans[\"text\"]: None for ans in qa[\"answers\"]}\n",
    "                    n_qs += 1\n",
    "                    fout.write(\n",
    "                        json.dumps({\n",
    "                            \"doc\": doc_text,\n",
    "                            \"doc_id\": doc_id,\n",
    "                            \"question\": qa[\"question\"],\n",
    "                            \"question_id\": qa[\"id\"],\n",
    "                            \"answers\": list(answers.keys())\n",
    "                        })\n",
    "                    )\n",
    "                    # if n_qs >= MAX_QS:\n",
    "                    break  # Always take at most one question from each paragraph\n",
    "                # if n_qs >= MAX_QS:\n",
    "                break  # Always take at most one question from each document\n",
    "            if n_qs >= MAX_QS:\n",
    "                break\n",
    "\n",
    "print(f\"Got {n_qs} questions from {n_docs} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "433094cc-85ab-4b26-8054-a5b594d8e5c8",
   "metadata": {},
   "source": [
    "## Converting between JSON and XLSX\n",
    "\n",
    "JSON/JSON-Lines files are well-structured to use from code, but business users would typically be more comfortable building and maintaining datasets in spreadsheets to avoid having to add extra notation to their example texts.\n",
    "\n",
    "As shown in the snippet below, it's pretty straightforward to convert between JSON-Lines and **CSV** - which may be sufficient for some use-cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c59c728-de33-4032-83cf-7ec3ad4aaeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"question-answering/qa.manifest.jsonl\") as fin:\n",
    "    with open(\"question-answering/qa.csv\", \"w\") as fout:\n",
    "        writer = csv.writer(fout)\n",
    "        writer.writerow([\"Question\", \"Reference Answer(s)\", \"Source Doc ID\"])\n",
    "        for line in fin:\n",
    "            datum = json.loads(line)\n",
    "            writer.writerow([datum[\"question\"], \"<OR>\".join(datum[\"answers\"]), datum[\"doc_id\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf66c1-985b-4fe1-ac76-085c692b47e7",
   "metadata": {},
   "source": [
    "...But new users often experience issues (for example [with large numbers](https://answers.microsoft.com/en-us/msoffice/forum/all/microsoft-excel-corrupts-data-in-csv-files/8337e85c-b1f5-4e99-9ca4-1ab51ae2984e) or [non-ASCII characters like smart-quotes](https://answers.microsoft.com/en-us/msoffice/forum/all/csv-opening-in-excel-corrupts-the-text/18b997a2-a6fb-4d4c-8ffd-a40176961421)) when working in CSV data in common spreadsheet applications like Excel.\n",
    "\n",
    "We can simplify the editing experience by exporting directly into native Excel formats, using the open-source [openpyxl](https://openpyxl.readthedocs.io/en/stable/) library as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee52c4e-5ab8-4b32-8b29-49f01b1d0a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"question-answering/qa.manifest.jsonl\") as fin:\n",
    "    wb = openpyxl.Workbook()\n",
    "    ws = wb.active\n",
    "    ws.title = \"Test Cases\"\n",
    "\n",
    "    # Push the data:\n",
    "    ws[\"A1\"] = \"Question\"\n",
    "    ws[\"B1\"] = \"Reference Answer(s)\"\n",
    "    ws[\"C1\"] = \"Source Doc ID\"\n",
    "    for ix, line in enumerate(fin):\n",
    "        datum = json.loads(line)\n",
    "        ws[f\"A{ix+2}\"] = datum[\"question\"]\n",
    "        ws[f\"B{ix+2}\"] = \"<OR>\".join(datum[\"answers\"])\n",
    "        ws[f\"C{ix+2}\"] = datum[\"doc_id\"]\n",
    "\n",
    "    # Configure the Table (optional but nice for recording the semantics of the data)\n",
    "    tab = openpyxl.worksheet.table.Table(displayName=\"tbl_annotations\", ref=f\"A1:C{ix+2}\")\n",
    "    tab.tableStyleInfo = openpyxl.worksheet.table.TableStyleInfo(\n",
    "        name=\"TableStyleLight1\",\n",
    "        showFirstColumn=False,\n",
    "        showLastColumn=False,\n",
    "        showColumnStripes=False,\n",
    "        showRowStripes=True,\n",
    "    )\n",
    "    ws.add_table(tab)\n",
    "\n",
    "    # Save the file:\n",
    "    wb.save(\"question-answering/qa.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137438da-7823-474c-9d60-704b5580c36e",
   "metadata": {},
   "source": [
    "Since XLSX is a more open-ended format, converting back to JSON(L) requires deciding how strict or flexible you'd like to be in parsing out your desired structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f81c24a5-6c1d-4cff-b7e7-103f8fb3345d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'question': 'In what country is Normandy located?', 'answers': 'France', 'doc_id': 'Normans'}\n",
      "{'question': 'What branch of theoretical computer science deals with broadly classifying computational problems by difficulty and class of relationship?', 'answers': 'Computational complexity theory', 'doc_id': 'Computational_complexity_theory'}\n",
      "{'question': 'What is Southern California often abbreviated as?', 'answers': 'SoCal', 'doc_id': 'Southern_California'}\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "def read_excel_annotations(filepath: str) -> List[Dict]:\n",
    "    annotations_wb = openpyxl.load_workbook(filepath)\n",
    "    annotations_ws = annotations_wb.active  # Assume default active worksheet ('Sheet1' or etc) is the target\n",
    "\n",
    "    # You could spend a lot of time building fancy logic to auto-detect which worksheet, columns,\n",
    "    # rows to read data from... But 'tables' are a nice semantic way to structure data in\n",
    "    # spreadsheets so here we'll use that. See also:\n",
    "    # https://support.microsoft.com/en-us/office/overview-of-excel-tables-7ab0bb7d-3a9e-4b56-a3c9-6c94334e492c\n",
    "    # https://openpyxl.readthedocs.io/en/stable/worksheet_tables.html\n",
    "    try:\n",
    "        # Just take the first 'Table' to appear in the worksheet's .tables name:table dictionary:\n",
    "        annotations_tbl = next(val for val in annotations_ws.tables.values())\n",
    "        # Check the headers are as we expect:\n",
    "        expected_header_substrs = [\n",
    "            \"Question\", \"Reference Answer\", \"Source\",\n",
    "        ]\n",
    "        for ixcol, substr in enumerate(expected_header_substrs):\n",
    "            assert substr in annotations_tbl.column_names[ixcol], \\\n",
    "                \"Expected column {} of table {} to have '{}' in title. Got '{}'\".format(\n",
    "                    ixcol, annotations_tbl.name, substr, annotations_tbl.column_names[ixcol]\n",
    "                )\n",
    "        # Fetch the data cells from the table:\n",
    "        start_row_offset = annotations_tbl.headerRowCount\n",
    "        end_row_offset = -annotations_tbl.totalsRowCount if annotations_tbl.totalsRowCount else None\n",
    "        data_cells = annotations_ws[annotations_tbl.ref][start_row_offset:end_row_offset]\n",
    "        results = []\n",
    "        for ixrow, row_cells in enumerate(data_cells):\n",
    "            # Skip blank lines:\n",
    "            if all(not cell.value for cell in row_cells):\n",
    "                continue\n",
    "            # Append record:\n",
    "            results.append({\n",
    "                \"question\": row_cells[0].value,\n",
    "                \"answers\": row_cells[1].value,\n",
    "                \"doc_id\": row_cells[2].value,\n",
    "            })\n",
    "        return results\n",
    "    except Exception as err:\n",
    "        raise ValueError(\n",
    "            \"Failed to read annotation data from spreadsheet - maybe you need to update the logic or \"\n",
    "            \"make your spreadsheet consistent with it?\"\n",
    "        ) from err\n",
    "\n",
    "\n",
    "annotations = read_excel_annotations(\"question-answering/qa.xlsx\")\n",
    "for ix, ann in enumerate(annotations):\n",
    "    print(ann)\n",
    "    if ix >= 2:\n",
    "        print(\"...\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee678cc8-207d-4fc5-ac7b-bddfe3cb1034",
   "metadata": {},
   "source": [
    "## From dataset and prompt template to model inputs\n",
    "\n",
    "To answer questions from source data with our Large Language Model, we'll use a **prompt template** to combine:\n",
    "\n",
    "1. General persona-setting guidance about how the bot should behave and respond to the question (sometimes called a \"system message\" or \"system context\")\n",
    "2. The source document\n",
    "3. The user's question to be answered\n",
    "\n",
    "This prompt template may be refined over multiple rounds of review by comparing the evaluation result.\n",
    "\n",
    "The cell below applies the draft prompt template to produce a dataset of:\n",
    "\n",
    "```json\n",
    "{\n",
    "    \"prompt\": {\n",
    "        \"text\": \"...\",  // Final prompt input to the LLM - after RAG and prompt templating\n",
    "    },\n",
    "    \"referenceResponse\": {\n",
    "        \"text\": \"...\"  // Expected 'ground truth' answer(s) from the model for this question\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "This format is [ready to be used with Amazon SageMaker Foundation Model Evaluation jobs](https://docs.aws.amazon.com/sagemaker/latest/dg/clarify-foundation-model-evaluate-human.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a8d8d6-b3a8-45c6-9c87-8df9f53ee425",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = Template(\"\"\"Human:\n",
    "You are Friendo, a helpful assistant from AnyCompany. Answer the question below based on the\n",
    "following AnyCompany documentation, or if the answer isn't present in the documentation, you can\n",
    "say you don't know.\n",
    "\n",
    "<document>\n",
    "${doc}\n",
    "</document>\n",
    "\n",
    "<question>\n",
    "${question}\n",
    "</question>\n",
    "\n",
    "Assistant:\n",
    "\"\"\")\n",
    "\n",
    "with open(\"question-answering/qa.manifest.jsonl\") as fin:\n",
    "    with open(\"question-answering/eval-job-input-qa.manifest.jsonl\", \"w\") as fout:\n",
    "        for ix, line in enumerate(fin):\n",
    "            raw_datum = json.loads(line)\n",
    "            if ix > 0:\n",
    "                fout.write(\"\\n\")\n",
    "            # TODO: Use prompt_template.get_identifiers() in Python 3.11+\n",
    "            # It'd be better to filter the substitute() mapping dict by template vars rather than\n",
    "            # use safe_substitute (which swallows errors for missing mapping items as well as unused\n",
    "            # mapping items), but this feature is only available in Python 3.11+\n",
    "            fout.write(\n",
    "                json.dumps({\n",
    "                    \"prompt\": {\"text\": prompt_template.safe_substitute(raw_datum)},\n",
    "                    \"referenceResponse\": {\"text\": \"<OR>\".join(raw_datum[\"answers\"])},\n",
    "                })\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edd8abd8-3837-48f0-bad5-ade36e39f4bc",
   "metadata": {},
   "source": [
    "For **demonstrating human evaluation** jobs, even 20 examples might be a bit tedious to wade through in a workshop: So we'll create an even shorter dataset for that as a separate file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0b1c50-b6b8-4406-9eb7-b732c55c9f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"question-answering/eval-job-input-qa.manifest.jsonl\") as fin:\n",
    "    with open(\"question-answering/human-demo-input-qa-sagemaker.manifest.jsonl\", \"w\") as fout:\n",
    "        for ix, line in enumerate(fin):\n",
    "            if ix >= 10:\n",
    "                break\n",
    "            if ix > 0:\n",
    "                fout.write(\"\\n\")\n",
    "            fout.write(line.strip())\n",
    "print(f\"Wrote {ix} records to human demo file for SageMaker\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b22b3f7-f5ae-4a85-bef8-cda5e2f8e6c7",
   "metadata": {},
   "source": [
    "Unfortunately (as documented [here in the Bedrock User Guide](https://docs.aws.amazon.com/bedrock/latest/userguide/model-evaluation-prompt-datasets-custom.html)), Bedrock Foundation Model Evaluation Jobs use a slightly different format where both `prompt` and `referenceResponse` should be a plain string instead of an object\n",
    "\n",
    "In the cell below we'll copy and transform the SageMaker manifest to create one that's suitable for Bedrock too:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cd480f-ef02-4dfb-b690-16b2a96ae5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"question-answering/human-demo-input-qa-sagemaker.manifest.jsonl\") as fin:\n",
    "    with open(\"question-answering/human-demo-input-qa-bedrock.manifest.jsonl\", \"w\") as fout:\n",
    "        for ix, line in enumerate(fin):\n",
    "            if ix > 0:\n",
    "                fout.write(\"\\n\")\n",
    "            record = json.loads(line)\n",
    "            for field in (\"prompt\", \"referenceResponse\"):\n",
    "                if field in record:\n",
    "                    record[field] = record[field][\"text\"]\n",
    "            fout.write(json.dumps(record))\n",
    "print(f\"Wrote {ix + 1} records to human demo file for Bedrock\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e0d33e-aac0-41c0-b2b2-8ae40e9195f9",
   "metadata": {},
   "source": [
    "## Using the data with Bedrock and SageMaker\n",
    "\n",
    "To actually create an Amazon Bedrock or Amazon SageMaker model evaluation job from these manifest files, you'll first need to upload them to Amazon S3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6043522c-59d7-49ca-b24d-d60bad7aa1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# External Dependencies:\n",
    "import boto3  # AWS SDK for Python\n",
    "import sagemaker  # Amazon SageMaker high-level SDK\n",
    "\n",
    "s3 = boto3.resource(\"s3\")\n",
    "smsess = sagemaker.Session()\n",
    "bucket_name = smsess.default_bucket()  # (You could specify a custom bucket name instead)\n",
    "prefix = \"llm-eval/demo/squad\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56501ac-cea3-4d6c-8fa8-890ded2f9da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp question-answering/human-demo-input-qa-bedrock.manifest.jsonl \\\n",
    "    s3://{bucket_name}/{prefix}/input-bedrock.manifest.jsonl\n",
    "!aws s3 cp question-answering/human-demo-input-qa-sagemaker.manifest.jsonl \\\n",
    "    s3://{bucket_name}/{prefix}/input-sagemaker.manifest.jsonl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf5a8a2-f656-4b3f-8132-e9d69e58ba44",
   "metadata": {},
   "source": [
    "### Review automated analysis results\n",
    "\n",
    "Once you've created and finished an evaluation job using the above input manifest URI, you can also consider downloading the results to the notebook for analysis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ac3842-7646-4c70-b4cd-e8900e51e3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Replace the results_uri with your job's generated output location!\n",
    "results_uri = f\"s3://{bucket_name}/llm-eval/demo/squad/results/za6h418kkvak/datasets/\"\n",
    "acc_results_uri = f\"{results_uri}dataset1/output.jsonl\"\n",
    "acc_results_key = acc_results_uri[len(\"s3://\"):].partition(\"/\")[2]\n",
    "tox_results_uri = f\"{results_uri}dataset2/output.jsonl\"\n",
    "tox_results_key = acc_results_uri[len(\"s3://\"):].partition(\"/\")[2]\n",
    "\n",
    "os.makedirs(\"results/squad\", exist_ok=True)\n",
    "s3.Bucket(bucket_name).download_file(acc_results_key, \"results/squad/auto-result-acc.output.jsonl\")\n",
    "s3.Bucket(bucket_name).download_file(tox_results_key, \"results/squad/auto-result-tox.output.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ec1da4-2b6b-42fe-885f-0719e22f7d79",
   "metadata": {},
   "source": [
    "In this example the default Accuracy measure seems to be **penalizing the model** for providing answers that are much more verbose than the reference: Scores are low despite the answers usually seeming correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "496ea3c6-f759-4c74-93a6-4280cb2e9b29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_output</th>\n",
       "      <th>model_output</th>\n",
       "      <th>score_acc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>France</td>\n",
       "      <td>Based on the documentation provided, Normandy is located in Franc...</td>\n",
       "      <td>0.083333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Computational complexity theory</td>\n",
       "      <td>Based on the documentation, computational complexity theory is th...</td>\n",
       "      <td>0.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SoCal</td>\n",
       "      <td>Based on the document, Southern California is often abbreviated a...</td>\n",
       "      <td>0.068966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BSkyB</td>\n",
       "      <td>According to the document, the company formed by the merger of Sk...</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>highly diversified&lt;OR&gt;diversified</td>\n",
       "      <td>Based on the information in the AnyCompany documentation, Victori...</td>\n",
       "      <td>0.049383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the southern and central parts of France&lt;OR&gt;about one-eighth&lt;OR&gt;so...</td>\n",
       "      <td>Based on the passage, the Huguenot population in France was large...</td>\n",
       "      <td>0.324324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>solar power, nuclear power or geothermal energy&lt;OR&gt;solar&lt;OR&gt;solar ...</td>\n",
       "      <td>Based on the documentation, solar power is noted as a non-combust...</td>\n",
       "      <td>0.266667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Based on the documentation provided, the atomic number of oxygen ...</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1973&lt;OR&gt;October 1973&lt;OR&gt;October</td>\n",
       "      <td>According to the document, the 1973 oil crisis began in October 1...</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a body of treaties and legislation, such as Regulations and Direct...</td>\n",
       "      <td>European Union law is a system of laws that apply to the member s...</td>\n",
       "      <td>0.189781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amazonia or the Amazon Jungle&lt;OR&gt;also known in English as Amazonia...</td>\n",
       "      <td>Based on the documentation, another name used to describe the Ama...</td>\n",
       "      <td>0.339623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>comb jellies&lt;OR&gt;phylum of animals that live in marine waters&lt;OR&gt;a ...</td>\n",
       "      <td>Based on the given document, a ctenophora is a type of marine ani...</td>\n",
       "      <td>0.109091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Fresno</td>\n",
       "      <td>According to the passage, Fresno is the fifth-largest city in Cal...</td>\n",
       "      <td>0.064516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the concept Distributed Adaptive Message Block Switching&lt;OR&gt;Paul B...</td>\n",
       "      <td>Based on the documentation provided, Paul Baran developed the con...</td>\n",
       "      <td>0.264706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Central Asia&lt;OR&gt;the arid plains of Central Asia</td>\n",
       "      <td>Based on the document, the Black Death is thought to have origina...</td>\n",
       "      <td>0.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rock crystallizes from melt (magma and/or lava)&lt;OR&gt;melt (magma and...</td>\n",
       "      <td>Based on the information provided in the geology documentation, a...</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>its root word pharma&lt;OR&gt;pharma</td>\n",
       "      <td>According to the document, the word pharmacy is derived from its ...</td>\n",
       "      <td>0.258065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Civil disobedience</td>\n",
       "      <td>Based on the documentation, civil disobedience is when people in ...</td>\n",
       "      <td>0.129032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Construction</td>\n",
       "      <td>Based on the document, construction is the process of constructin...</td>\n",
       "      <td>0.019802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>independent schools&lt;OR&gt;independent</td>\n",
       "      <td>Based on the documentation provided, another name for private sch...</td>\n",
       "      <td>0.072727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>John Harvard</td>\n",
       "      <td>Based on the passage, Harvard University is named after John Harv...</td>\n",
       "      <td>0.108108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>Based on the information in the document, the largest city by pop...</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>40%&lt;OR&gt;40</td>\n",
       "      <td>According to the document, a study by the World Institute for Dev...</td>\n",
       "      <td>0.066667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>private research university&lt;OR&gt;private research&lt;OR&gt;a private resea...</td>\n",
       "      <td>Based on the documentation, the University of Chicago is a privat...</td>\n",
       "      <td>0.101695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Yuán Cháo&lt;OR&gt;元朝</td>\n",
       "      <td>The Chinese name for the Yuan dynasty is 元朝 (Yuán Cháo). This is ...</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>disease</td>\n",
       "      <td>Based on the document, the immune system protects organisms again...</td>\n",
       "      <td>0.020000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>the United Nations</td>\n",
       "      <td>Based on the document, the IPCC is under the auspices of the Unit...</td>\n",
       "      <td>0.102564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>itself</td>\n",
       "      <td>According to the documentation, a prime number is a natural numbe...</td>\n",
       "      <td>0.080000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>the North Sea in the Netherlands&lt;OR&gt;North Sea</td>\n",
       "      <td>Based on the documentation provided, the Rhine eventually empties...</td>\n",
       "      <td>0.105263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Following a referendum in 1997&lt;OR&gt;1998</td>\n",
       "      <td>The current Parliament of Scotland was convened by the Scotland A...</td>\n",
       "      <td>0.181818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Islamism</td>\n",
       "      <td>Based on the information in the document, an Islamic revival move...</td>\n",
       "      <td>0.045455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Latin</td>\n",
       "      <td>Based on the information provided in the document, the word \"impe...</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Warsaw</td>\n",
       "      <td>Based on the provided document, the largest city of Poland is War...</td>\n",
       "      <td>0.028986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1754–1763</td>\n",
       "      <td>According to the document, the French and Indian War was fought b...</td>\n",
       "      <td>0.042553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>force&lt;OR&gt;the concept of force</td>\n",
       "      <td>Based on the given documentation, the answer is that philosophers...</td>\n",
       "      <td>0.157895</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            target_output  \\\n",
       "0                                                                  France   \n",
       "1                                         Computational complexity theory   \n",
       "2                                                                   SoCal   \n",
       "3                                                                   BSkyB   \n",
       "4                                       highly diversified<OR>diversified   \n",
       "5   the southern and central parts of France<OR>about one-eighth<OR>so...   \n",
       "6   solar power, nuclear power or geothermal energy<OR>solar<OR>solar ...   \n",
       "7                                                                       8   \n",
       "8                                         1973<OR>October 1973<OR>October   \n",
       "9   a body of treaties and legislation, such as Regulations and Direct...   \n",
       "10  Amazonia or the Amazon Jungle<OR>also known in English as Amazonia...   \n",
       "11  comb jellies<OR>phylum of animals that live in marine waters<OR>a ...   \n",
       "12                                                                 Fresno   \n",
       "13  the concept Distributed Adaptive Message Block Switching<OR>Paul B...   \n",
       "14                        Central Asia<OR>the arid plains of Central Asia   \n",
       "15  rock crystallizes from melt (magma and/or lava)<OR>melt (magma and...   \n",
       "16                                         its root word pharma<OR>pharma   \n",
       "17                                                     Civil disobedience   \n",
       "18                                                           Construction   \n",
       "19                                     independent schools<OR>independent   \n",
       "20                                                           John Harvard   \n",
       "21                                                           Jacksonville   \n",
       "22                                                              40%<OR>40   \n",
       "23  private research university<OR>private research<OR>a private resea...   \n",
       "24                                                        Yuán Cháo<OR>元朝   \n",
       "25                                                                disease   \n",
       "26                                                     the United Nations   \n",
       "27                                                                 itself   \n",
       "28                          the North Sea in the Netherlands<OR>North Sea   \n",
       "29                                 Following a referendum in 1997<OR>1998   \n",
       "30                                                               Islamism   \n",
       "31                                                                  Latin   \n",
       "32                                                                 Warsaw   \n",
       "33                                                              1754–1763   \n",
       "34                                          force<OR>the concept of force   \n",
       "\n",
       "                                                             model_output  \\\n",
       "0    Based on the documentation provided, Normandy is located in Franc...   \n",
       "1    Based on the documentation, computational complexity theory is th...   \n",
       "2    Based on the document, Southern California is often abbreviated a...   \n",
       "3    According to the document, the company formed by the merger of Sk...   \n",
       "4    Based on the information in the AnyCompany documentation, Victori...   \n",
       "5    Based on the passage, the Huguenot population in France was large...   \n",
       "6    Based on the documentation, solar power is noted as a non-combust...   \n",
       "7    Based on the documentation provided, the atomic number of oxygen ...   \n",
       "8    According to the document, the 1973 oil crisis began in October 1...   \n",
       "9    European Union law is a system of laws that apply to the member s...   \n",
       "10   Based on the documentation, another name used to describe the Ama...   \n",
       "11   Based on the given document, a ctenophora is a type of marine ani...   \n",
       "12   According to the passage, Fresno is the fifth-largest city in Cal...   \n",
       "13   Based on the documentation provided, Paul Baran developed the con...   \n",
       "14   Based on the document, the Black Death is thought to have origina...   \n",
       "15   Based on the information provided in the geology documentation, a...   \n",
       "16   According to the document, the word pharmacy is derived from its ...   \n",
       "17   Based on the documentation, civil disobedience is when people in ...   \n",
       "18   Based on the document, construction is the process of constructin...   \n",
       "19   Based on the documentation provided, another name for private sch...   \n",
       "20   Based on the passage, Harvard University is named after John Harv...   \n",
       "21   Based on the information in the document, the largest city by pop...   \n",
       "22   According to the document, a study by the World Institute for Dev...   \n",
       "23   Based on the documentation, the University of Chicago is a privat...   \n",
       "24   The Chinese name for the Yuan dynasty is 元朝 (Yuán Cháo). This is ...   \n",
       "25   Based on the document, the immune system protects organisms again...   \n",
       "26   Based on the document, the IPCC is under the auspices of the Unit...   \n",
       "27   According to the documentation, a prime number is a natural numbe...   \n",
       "28   Based on the documentation provided, the Rhine eventually empties...   \n",
       "29   The current Parliament of Scotland was convened by the Scotland A...   \n",
       "30   Based on the information in the document, an Islamic revival move...   \n",
       "31   Based on the information provided in the document, the word \"impe...   \n",
       "32   Based on the provided document, the largest city of Poland is War...   \n",
       "33   According to the document, the French and Indian War was fought b...   \n",
       "34   Based on the given documentation, the answer is that philosophers...   \n",
       "\n",
       "    score_acc  \n",
       "0    0.083333  \n",
       "1    0.101695  \n",
       "2    0.068966  \n",
       "3    0.066667  \n",
       "4    0.049383  \n",
       "5    0.324324  \n",
       "6    0.266667  \n",
       "7    0.080000  \n",
       "8    0.129032  \n",
       "9    0.189781  \n",
       "10   0.339623  \n",
       "11   0.109091  \n",
       "12   0.064516  \n",
       "13   0.264706  \n",
       "14   0.312500  \n",
       "15   0.500000  \n",
       "16   0.258065  \n",
       "17   0.129032  \n",
       "18   0.019802  \n",
       "19   0.072727  \n",
       "20   0.108108  \n",
       "21   0.100000  \n",
       "22   0.066667  \n",
       "23   0.101695  \n",
       "24   0.105263  \n",
       "25   0.020000  \n",
       "26   0.102564  \n",
       "27   0.080000  \n",
       "28   0.105263  \n",
       "29   0.181818  \n",
       "30   0.045455  \n",
       "31   0.100000  \n",
       "32   0.028986  \n",
       "33   0.042553  \n",
       "34   0.157895  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 70\n",
    "\n",
    "auto_acc_records = []\n",
    "with open(\"results/squad/auto-result-acc.output.jsonl\") as f:\n",
    "    for line in f:\n",
    "        datum = json.loads(line)\n",
    "        auto_acc_records.append({\n",
    "            \"target_output\": datum[\"inputRecord\"][\"referenceResponse\"],\n",
    "            \"model_output\": datum[\"modelInvocations\"][0][\"responseText\"],\n",
    "            \"score_acc\": next(\n",
    "                s for s in datum[\"automatedEvaluationResult\"][\"scores\"] if s[\"metricName\"] == \"Accuracy\"\n",
    "            )[\"result\"],\n",
    "        })\n",
    "out_df = pd.DataFrame(auto_acc_records)\n",
    "out_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a92fea-3ef8-4a11-a7eb-c71bc51d4766",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
